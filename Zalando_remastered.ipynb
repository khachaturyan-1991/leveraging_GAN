{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5977,
     "status": "ok",
     "timestamp": 1680779554541,
     "user": {
      "displayName": "Ruben Khachaturyan",
      "userId": "02796732287126401211"
     },
     "user_tz": -120
    },
    "id": "0TMQp_tRetA7",
    "outputId": "c2a2dc00-67c0-4174-ac59-fe1c3c269db2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:08:10.862776: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P-1lmq9ofiMl"
   },
   "outputs": [],
   "source": [
    "data_dir = \"./zalando/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21102,
     "status": "ok",
     "timestamp": 1680779575931,
     "user": {
      "displayName": "Ruben Khachaturyan",
      "userId": "02796732287126401211"
     },
     "user_tz": -120
    },
    "id": "yajdhx4gfiKq",
    "outputId": "1dd232bb-ab46-4950-8c07-26f49965807d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5051 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:08:15.449543: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "imsize = 32\n",
    "batch_size = 32\n",
    "latent_dim = 100\n",
    "\n",
    "train_images = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir, label_mode=None, image_size=(imsize,imsize), batch_size=32)\n",
    "train_images = train_images.map(lambda x: (x - 127.5) / 127.5)\n",
    "weight_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1680779576407,
     "user": {
      "displayName": "Ruben Khachaturyan",
      "userId": "02796732287126401211"
     },
     "user_tz": -120
    },
    "id": "AVnuez1MfiGn",
    "outputId": "4fd56cf1-d591-4b3f-9fe1-0053ec85e61f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "    model = keras.models.Sequential(name='generator')\n",
    "\n",
    "    model.add(keras.layers.Dense(4*4*256, input_dim=latent_dim))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Reshape([4,4,256]))\n",
    "\n",
    "    model.add(keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),\n",
    "                                           padding='same',kernel_initializer=weight_init,\n",
    "                                           activation = keras.layers.ReLU()))\n",
    "    \n",
    "    model.add(keras.layers.Conv2DTranspose(64, (4,4), strides=(2,2),\n",
    "                                           padding='same',kernel_initializer=weight_init,\n",
    "                                           activation = keras.layers.ReLU()))\n",
    "    \n",
    "    model.add(keras.layers.Conv2DTranspose(32, (4,4), strides=(2,2),\n",
    "                                           padding='same',\n",
    "                                           kernel_initializer=weight_init,\n",
    "                                           activation = keras.layers.ReLU()))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "    \n",
    "    return model\n",
    "    \n",
    "generator = build_generator()\n",
    "\n",
    "def build_discriminator():\n",
    "    \n",
    "    model = keras.models.Sequential(name = 'discriminator')\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, (4,4), padding='same',\n",
    "                                 strides=(2,2), input_shape=(imsize, imsize, 3)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(256, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(256, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fec0be581c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in train_images:\n",
    "    img = i\n",
    "\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1680779576408,
     "user": {
      "displayName": "Ruben Khachaturyan",
      "userId": "02796732287126401211"
     },
     "user_tz": -120
    },
    "id": "SPVCpUGbGYl3",
    "outputId": "eb5f8d15-e434-4444-d24b-7f319b970cff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.5084534 ],\n",
       "       [0.497366  ],\n",
       "       [0.4879597 ],\n",
       "       [0.46727324]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = tf.random.normal(shape=[1, latent_dim])\n",
    "#img = generator(noise)\n",
    "discriminator(img[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(32,32,3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49994916]], dtype=float32)>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_generator():\n",
    "\n",
    "    model = keras.models.Sequential(name='generator')\n",
    "\n",
    "    model.add(keras.layers.Dense(32*32*3, input_dim=100))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Reshape([32,32,3]))\n",
    "\n",
    "    model.add(base_model)\n",
    "\n",
    "    for f in [512, 256, 128, 64, 32]:\n",
    "        model.add(keras.layers.Conv2DTranspose(f, (4,4), strides=(2,2),\n",
    "                                               padding='same',kernel_initializer=weight_init,\n",
    "                                               activation = keras.layers.ReLU()))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "noise = tf.random.normal(shape=(1, 100), seed=42)\n",
    "imgs = generator(noise)\n",
    "print(imgs.shape)\n",
    "discriminator(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triple"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gen = [inp100, vgg, |||, out32]\n",
    "dis = [inp32, vgg, |||, out1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Composed generator\n",
    "def build_gen_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_untrainbale')\n",
    "\n",
    "    model.add(keras.layers.Dense(32*32*3, input_dim=100))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Reshape([32,32,3]))\n",
    "\n",
    "    model.add(base_model)\n",
    "\n",
    "    return model\n",
    "\n",
    "gen_in = build_gen_untrainable()\n",
    "\n",
    "def build_gen_trainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (1, 1, 512)))\n",
    "    model.add(keras.layers.Dense(32*32*3))\n",
    "    for f in [512, 256, 128, 64, 32]:\n",
    "        model.add(keras.layers.Conv2DTranspose(f, (4,4), strides=(2,2),\n",
    "                                               padding='same',kernel_initializer=weight_init,\n",
    "                                               activation = keras.layers.ReLU()))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(keras.layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "gen_out = build_gen_trainbale()\n",
    "\n",
    "mm = keras.models.Sequential([gen_in,gen_out])\n",
    "noise = tf.random.normal(shape=(1,100))\n",
    "img = mm(noise)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composed discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dis_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name = 'discriminator')\n",
    "\n",
    "    model.add(base_model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "dis_in = build_dis_untrainable()\n",
    "\n",
    "def build_dis_untrainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (1, 1, 512)))\n",
    "    \n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(256, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(256, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "dis_out = build_dis_untrainable()\n",
    "\n",
    "# dd = keras.Sequential([dis_in,dis_out])\n",
    "# dd(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(keras.Model):\n",
    "\n",
    "    def __init__(self, gen_in, gen_out, dis_in, dis_out):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.latent_dim = 100\n",
    "        self.gen_in = gen_in\n",
    "        self.gen_out = gen_out\n",
    "        self.dis_in = dis_in\n",
    "        self.dis_out = dis_out\n",
    "        self.dis_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.gen_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    def compile(self, gen_out_optim, dis_out_optim, loss):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.gen_out_opt = gen_out_optim\n",
    "        self.dis_out_opt = dis_out_optim\n",
    "        self.loss = loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.dis_loss_metric, self.gen_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        \n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            pre = self.gen_in(noise)\n",
    "            fake_img = self.gen_out(pre, training = True)\n",
    "            pre = self.dis_in(fake_img)\n",
    "            predict_on_fake = self.dis_out(pre, training = True)\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            fake_loss = self.loss(predict_on_fake, fake_labels)\n",
    "            real_lables = tf.ones((batch_size, 1))\n",
    "            pre = self.dis_in(real_images, training = True)\n",
    "            predict_on_real = self.dis_out(pre, training = True)\n",
    "            real_loss = self.loss(predict_on_real, real_lables)\n",
    "            total_loss = (fake_loss + real_loss)/2\n",
    "        grads = tape.gradient(total_loss, self.dis_out .trainable_variables)\n",
    "        self.dis_out_opt.apply_gradients(zip(grads, self.dis_out.trainable_variables))\n",
    "        self.dis_loss_metric.update_state(total_loss)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            pre = self.gen_in(noise)\n",
    "            fake_img = self.gen_out(pre, training = True)\n",
    "            pre = self.dis_in(fake_img)\n",
    "            predict_on_fake = self.dis_out(pre, training = True)\n",
    "            fake_lables = tf.ones((batch_size, 1))\n",
    "            total_loss = self.loss(fake_lables, predict_on_fake)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.gen_in.trainable_variables)\n",
    "        self.gen_out_opt.apply_gradients(zip(grads, self.gen_in.trainable_variables))\n",
    "        self.gen_loss_metric.update_state(total_loss)\n",
    "\n",
    "        return {\"d_loss\": self.dis_loss_metric.result(), \"g_loss\": self.gen_loss_metric.result()}\n",
    "\n",
    "dcgan = DCGAN(gen_in, gen_out, dis_in, dis_out)\n",
    "\n",
    "dcgan.compile(\n",
    "    gen_out_optim =keras.optimizers.Adam(learning_rate=0.008, beta_1 = 0.5),\n",
    "    dis_out_optim=keras.optimizers.Adam(learning_rate=0.003, beta_1 = 0.5),\n",
    "    loss=keras.losses.BinaryCrossentropy())\n",
    "\n",
    "dcgan.fit(train_images, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triple2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "let us now take less layers from the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x7fea7b259510>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7fea7b26d510>,\n",
       " <keras.layers.convolutional.conv2d.Conv2D at 0x7feb87c65240>,\n",
       " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7fea7b258be0>]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(32,32,3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "vgg_layers = []\n",
    "for layer in base_model.layers[:4]:\n",
    "    layer.trainable = False\n",
    "    vgg_layers.append(layer)\n",
    "\n",
    "vgg_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32, 32, 3])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Composed generator\n",
    "def build_gen_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_untrainbale')\n",
    "\n",
    "    model.add(keras.layers.Dense(32*32*3, input_dim=100))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Reshape([32,32,3]))\n",
    "\n",
    "    for layer in vgg_layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "gen_in = build_gen_untrainable()\n",
    "\n",
    "def build_gen_trainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (16, 16, 64)))\n",
    "    model.add(keras.layers.Dense(16*16*64))\n",
    "    model.add(keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),\n",
    "                                           padding='same',kernel_initializer=weight_init,\n",
    "                                           activation = keras.layers.ReLU()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "    return model\n",
    "\n",
    "gen_out = build_gen_trainable()\n",
    "\n",
    "mm = keras.models.Sequential([gen_in, gen_out])\n",
    "img = mm(noise)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.99596614]], dtype=float32)>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_dis_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name = 'dis_untrainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (32, 32, 3)))\n",
    "    for layer in vgg_layers:\n",
    "        model.add(layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "dis_in = build_dis_untrainable()\n",
    "\n",
    "def build_dis_trainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (16,16,64)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(keras.layers.Conv2D(256, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "dis_out = build_dis_trainable()\n",
    "\n",
    "dd = keras.Sequential([dis_in,dis_out])\n",
    "dd(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## triple3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.vgg16.VGG16(\n",
    "    weights='imagenet',\n",
    "    input_shape=(32,32,3),\n",
    "    include_top=False\n",
    ")\n",
    "\n",
    "vgg_layers = []\n",
    "for layer in base_model.layers[:4]:\n",
    "    layer.trainable = False\n",
    "    vgg_layers.append(layer)\n",
    "\n",
    "vgg_layers\n",
    "\n",
    "# Composed generator\n",
    "def build_gen_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_untrainbale')\n",
    "\n",
    "    model.add(keras.layers.Dense(32*32*3, input_dim=100))\n",
    "    model.add(keras.layers.ReLU())\n",
    "    \n",
    "    model.add(keras.layers.Reshape([32,32,3]))\n",
    "\n",
    "    for layer in vgg_layers:\n",
    "        model.add(layer)\n",
    "\n",
    "    return model\n",
    "\n",
    "gen_in = build_gen_untrainable()\n",
    "for layer in gen_in.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "def build_gen_trainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='gen_trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (16, 16, 64)))\n",
    "    model.add(keras.layers.Dense(16*16*64))\n",
    "    model.add(keras.layers.Dense(8*8*32))\n",
    "    model.add(keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2),\n",
    "                                           padding='same',kernel_initializer=weight_init,\n",
    "                                           activation = keras.layers.ReLU()))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Conv2D(3, (4, 4), padding=\"same\", activation=\"tanh\"))\n",
    "    return model\n",
    "\n",
    "gen_out = build_gen_trainable()\n",
    "\n",
    "def build_dis_untrainable():\n",
    "    \"\"\"\n",
    "    here an input shape (0,100) is passed thourh vgg\n",
    "    this part of the net remains untrainable\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name = 'dis_untrainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (32, 32, 3)))\n",
    "    for layer in vgg_layers:\n",
    "        model.add(layer)\n",
    "    \n",
    "    return model\n",
    "\n",
    "dis_in = build_dis_untrainable()\n",
    "for layer in dis_in.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "def build_dis_untrainable():\n",
    "    \"\"\"\n",
    "    here an input from the vgg part is passed\n",
    "    the trainbale layers\n",
    "    \"\"\"\n",
    "    model = keras.models.Sequential(name='trainbale')\n",
    "    model.add(keras.layers.InputLayer(input_shape = (16,16,64)))\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(keras.layers.Conv2D(128, (4,4), padding='same', strides=(2,2)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "dis_out = build_dis_untrainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true,
    "id": "btPDSCi8g8Xr",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "  7/158 [>.............................] - ETA: 1:14 - d_loss: 7.7125 - g_loss: 4.4713e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [135]\u001b[0m, in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m dcgan \u001b[38;5;241m=\u001b[39m DCGAN(generator\u001b[38;5;241m=\u001b[39mgenerator, discriminator\u001b[38;5;241m=\u001b[39mdiscriminator)\n\u001b[1;32m     53\u001b[0m dcgan\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     54\u001b[0m     gen_optim\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.008\u001b[39m, beta_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     55\u001b[0m     dis_optim\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m, beta_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m),  \n\u001b[1;32m     56\u001b[0m     loss\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy())\n\u001b[0;32m---> 58\u001b[0m \u001b[43mdcgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/gig/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class DCGAN(keras.Model):\n",
    "\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.latent_dim = 100\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.dis_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.gen_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    def compile(self, gen_optim, dis_optim, loss):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.gen_opt = gen_optim\n",
    "        self.dis_opt = dis_optim\n",
    "        self.loss = loss\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.dis_loss_metric, self.gen_loss_metric]\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        \n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            fake_img = self.generator(noise)\n",
    "            predict_on_fake = self.discriminator(fake_img, training = True)\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            fake_loss = self.loss(predict_on_fake, fake_labels)\n",
    "            real_lables = tf.ones((batch_size, 1))\n",
    "            predict_on_real = self.discriminator(real_images, training = True)\n",
    "            real_loss = self.loss(predict_on_real, real_lables)\n",
    "            total_loss = (fake_loss + real_loss)/2\n",
    "        grads = tape.gradient(total_loss, self.discriminator.trainable_variables)\n",
    "        self.dis_opt.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n",
    "        self.dis_loss_metric.update_state(total_loss)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            fake_img = self.generator(noise, training = True)\n",
    "            prediction_on_fake = self.discriminator(fake_img, training = False)\n",
    "            fake_lables = tf.ones((batch_size, 1))\n",
    "            total_loss = self.loss(fake_lables, prediction_on_fake)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.generator.trainable_variables)\n",
    "        self.gen_opt.apply_gradients(zip(grads, self.generator.trainable_variables))\n",
    "        self.gen_loss_metric.update_state(total_loss)\n",
    "\n",
    "        return {\"d_loss\": self.dis_loss_metric.result(), \"g_loss\": self.gen_loss_metric.result()}\n",
    "\n",
    "dcgan = DCGAN(generator=generator, discriminator=discriminator)\n",
    "\n",
    "dcgan.compile(\n",
    "    gen_optim=keras.optimizers.Adam(learning_rate=0.008, beta_1 = 0.5),\n",
    "    dis_optim=keras.optimizers.Adam(learning_rate=0.003, beta_1 = 0.5),  \n",
    "    loss=keras.losses.BinaryCrossentropy())\n",
    "\n",
    "dcgan.fit(train_images, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3S0AbB1hfh2v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O614UouXfhx5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK0ZIHjBfhve"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9sifsGxfhs5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__cXYJ2yfhqn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlWIae3ofhn4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO21jRdiV3KlhsCIPDfztQz",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "gig",
   "language": "python",
   "name": "gig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
